{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab Session 3 - Association Pattern Mining.ipynb","provenance":[{"file_id":"1YfIq77TsmV2D4vy7DCjrbb8Kp3EwN0ip","timestamp":1617159296995},{"file_id":"1aOeCyVtVHNIFPwT3_78jqaUe04Jrycx3","timestamp":1617159166159}],"authorship_tag":"ABX9TyN4wTjgsSNN1bIZJ/0zJKeo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YkUggi-NPis3"},"source":["# Association Analysis\n"]},{"cell_type":"code","metadata":{"id":"-_togNsO58HX"},"source":["# Menampilkan data\n","# Google Colab\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RlugQQLS6RZN"},"source":["import pandas as pd\n","data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/datasets/retail_dataset.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"As4I4Wwu6d8r"},"source":["data.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K3PL1UCuPszH"},"source":["Data NaN, Null, dan 0 pada kasus asosiasi bukanlah sebuah missing value atau noise yang harus dihilangkan atau diubah, tetapi perlu dilakukan pengkodean untuk mendapatkan data transaksi yang akan dicari asosiasinya"]},{"cell_type":"code","metadata":{"id":"A1SlWZMZ6mDm"},"source":["items = (data['0'].unique())\n","items"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Suhsp62S6xTI"},"source":["import numpy as np\n","from mlxtend.frequent_patterns import apriori, association_rules\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iGDfscgEP_Oe"},"source":["# One Hot Encode"]},{"cell_type":"code","metadata":{"id":"RfY7y3t3619g"},"source":["#Encode the itemset\n","itemset = set(items)\n","encoded_vals = []\n","for index, row in data.iterrows():\n","    rowset = set(row) \n","    labels = {}\n","    uncommons = list(itemset - rowset)\n","    commons = list(itemset.intersection(rowset))\n","    for uc in uncommons:\n","        labels[uc] = 0\n","    for com in commons:\n","        labels[com] = 1\n","    encoded_vals.append(labels)\n","encoded_vals[0]\n","ohe_data = pd.DataFrame(encoded_vals)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sz-UPzHkQVde"},"source":["# Applying Apriori"]},{"cell_type":"code","metadata":{"id":"Zg5v9UMD7GoN"},"source":["freq_items = apriori(ohe_data, min_support= 0.2, use_colnames=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1BfpvpovQFaV"},"source":["* ohe_data adalah data yang akan dianalisa asosiasinya\n","* min_support adalah minimum support yang akan ditentukan"]},{"cell_type":"code","metadata":{"id":"jHQPEl3O7Xr6"},"source":["freq_items"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sW16agCQ7bNK"},"source":["rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.6)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wnq2QYtGQwIv"},"source":["* min_threshold menentukan minimum confidence yang akan dicari asosiasinya\n","* min_support ditentukan/diatur di freq_item yang ditentukan di atas"]},{"cell_type":"code","metadata":{"id":"ZHiVjzcEQbpl"},"source":["rules"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rUOakipN7nM5"},"source":["#support vs confidence\n","plt.scatter(rules['support'], rules['confidence'], alpha=0.5)\n","plt.xlabel('support')\n","plt.ylabel('confidence')\n","plt.title('Support vs Confidence')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"maabMHlO7uN6"},"source":["#support vs lift\n","plt.scatter(rules['support'], rules['lift'], alpha=0.5)\n","plt.xlabel('support')\n","plt.ylabel('lift')\n","plt.title('Support vs Lift')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oO0P0u5E76nU"},"source":["#lift vs confidence\n","fit = np.polyfit(rules['lift'], rules['confidence'], 1)\n","fit_fn = np.poly1d(fit)\n","plt.plot(rules['lift'], rules['confidence'], 'yo', rules['lift'], \n"," fit_fn(rules['lift']))"],"execution_count":null,"outputs":[]}]}